如何是模型训练更稳定：即让梯度在合理的范围内
  将梯度乘法变成加法：ResNet、LSTM
  归一法:梯度归一化，梯度裁剪
  合理的权重初始化和激活函数

模型过拟合解决方案：
  增加数据集、数据增强（数据翻转、旋转，重要性采样）、dropout、减少模型参数量、权重衰退（L2正则）

梯度消失：
  batch normalization 批标准化

梯度爆炸：
  减小学习率

训练开始时计算不稳定：
  Xavier等 权重初始化

训练损失不降反而上升： 学习率过大或Adam计算不稳定
  减小学习率，不适用Adam优化器或Adam优化器中添加 amsgrad=True

模型训练发现 训练集和验证集都比以往模型好，但测试集效果不好：
  模型训练集和验证集都好不等于测试集也好，有些文章中也表现出这个特点
